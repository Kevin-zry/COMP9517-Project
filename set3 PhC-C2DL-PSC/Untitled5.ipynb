{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from sklearn.cluster import MeanShift\n",
    "from random import randint\n",
    "#from detector import Detectors\n",
    "from scipy.spatial import distance as dist\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=50):\n",
    "        self.nextId = 0\n",
    "        #self.vid = vid\n",
    "        #self.windows = windows\n",
    "        self.objects=OrderedDict()\n",
    "        self.disappeared=OrderedDict()\n",
    "        self.maxDisappeared=maxDisappeared \n",
    "        #self.trajectory=[self.objects[self.nextId]]\n",
    "        #self.tracker = self._init_tracker(windows, frame)\n",
    "    def register(self,center):\n",
    "        self.objects[self.nextId]=center\n",
    "        self.disappeared[self.nextId]=0\n",
    "        self.nextId+=1\n",
    "    def deregister(self,objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "    def update(self,cts):\n",
    "        #ok, new_box = self.tracker.update(frame)\n",
    "        dist_dict={}\n",
    "        if len(cts)==0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID]+=1\n",
    "                if self.disappeared[objectID]>self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "        inputCentroids = np.zeros((len(cts), 2), dtype=\"int\")\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(cts):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "        if len(self.objects)==0:\n",
    "            for i in range(0,len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        else:\n",
    "            objectIDs=list(self.objects.keys())\n",
    "            objectCenters=list(self.objects.values())\n",
    "            D = dist.cdist(np.array(objectCenters), inputCentroids)\n",
    "            #dist_dict={}\n",
    "            #dist_dict[self.objects.keys()]=D\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            usedRows=set()\n",
    "            usedCols=set()\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "                objectID=objectIDs[row]\n",
    "                self.objects[objectID]=inputCentroids[col]\n",
    "                self.disappeared[objectID]=0\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "            unusedRows=set(range(0,D.shape[0])).difference(usedRows)\n",
    "            unusedCols=set(range(0,D.shape[1])).difference(usedCols)\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                for row in unusedRows:\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "                    if self.disappeared[objectID]>self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features():\n",
    "   \n",
    "    def centercells(self,frame):\n",
    "        #contours2=contours_cells(frame)\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #Find connected domains\n",
    "            #comparing the area of connected domains\n",
    "        contours1=[] \n",
    "        centers=[]\n",
    "        for i in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(i)\n",
    "            if cv2.contourArea(i)>25:  #Remove small connected areas\n",
    "                #x, y, w, h = cv2.boundingRect(i)\n",
    "                contours1.append(i)\n",
    "        #centers=[]\n",
    "                for m,n in zip(contours1,range(len(contours1))):\n",
    "                    M = cv2.moments(m)\n",
    "                    cX=int(M[\"m10\"]/M[\"m00\"])\n",
    "                    cY=int(M[\"m01\"]/M[\"m00\"])\n",
    "                    #arr=np.array((cX,cY))\n",
    "                    centers.append((cX,cY))\n",
    "        #D=dist.cdist()\n",
    "        return centers\n",
    "    def perimetercells(self,frame):\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #Find connected domains\n",
    "            #comparing the area of connected domains\n",
    "        contours1=[] \n",
    "        plength=[]\n",
    "        for i in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(i)\n",
    "            if cv2.contourArea(i)>25:  #Remove small connected areas\n",
    "                #x, y, w, h = cv2.boundingRect(i)\n",
    "                contours1.append(i)\n",
    "        #contours3=contours_cells(frame)\n",
    "        #plength=[]\n",
    "                for m,n in zip(contours1,range(len(contours1))):\n",
    "                    M = cv2.moments(m)\n",
    "                    plength.append(cv2.arcLength(m,True))\n",
    "        return plength\n",
    "    \n",
    "    def areacells(self,frame):\n",
    "        #contours4=contours_cells(frame)\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #Find connected domains\n",
    "            #comparing the area of connected domains\n",
    "        contours1=[] \n",
    "        areas=[]\n",
    "        for i in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(i)\n",
    "            if cv2.contourArea(i)>25:  #Remove small connected areas\n",
    "                #x, y, w, h = cv2.boundingRect(i)\n",
    "                contours1.append(i)\n",
    "                for m,n in zip(contours1,range(len(contours1))):\n",
    "                    M = cv2.moments(m)\n",
    "                    areas.append(cv2.contourArea(m))\n",
    "        return areas\n",
    "    def ellipsecells(self,frame):\n",
    "        pi=3.1415926\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #Find connected domains\n",
    "            #comparing the area of connected domains\n",
    "        contours1=[] \n",
    "        P,A,Q=[],[],[]\n",
    "        for i in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(i)\n",
    "            if cv2.contourArea(i)>25:  #Remove small connected areas\n",
    "                #x, y, w, h = cv2.boundingRect(i)\n",
    "                contours1.append(i)\n",
    "                for m,n in zip(contours1,range(len(contours1))):\n",
    "                    M = cv2.moments(m)\n",
    "                    ellipse=cv2.fitEllipse(m)\n",
    "                    #ellipse[1][0]\n",
    "                    P.append(int(ellipse[1][0]*pi+2*(ellipse[1][1]-ellipse[1][0])))\n",
    "                    A.append(int(pi*ellipse[1][0]/2*ellipse[1][1]/2))\n",
    "                    for l in range(len(P)):\n",
    "                        #s=int(P[l]*P[l] /(4*pi * A[l]*A[l] ))\n",
    "                        Q.append(int(P[l]*P[l] /(4*pi * A[l]*A[l] )))\n",
    "        return Q\n",
    "    def minrect_angle(self,frame):\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #Find connected domains\n",
    "            #comparing the area of connected domains\n",
    "        contours1=[] \n",
    "        b=[]\n",
    "        for i in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(i)\n",
    "            if cv2.contourArea(i)>25:  #Remove small connected areas\n",
    "                #x, y, w, h = cv2.boundingRect(i)\n",
    "                contours1.append(i)\n",
    "        \n",
    "                for m,n in zip(contours1,range(len(contours1))):\n",
    "                    M = cv2.moments(m)\n",
    "                    rect=cv2.minAreaRect(m)\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    box_d = np.int0(box)\n",
    "                    b.append(box_d)\n",
    "        return b[2]\n",
    "    def rect_window(self,frame):\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #Find connected domains\n",
    "            #comparing the area of connected domains\n",
    "        contours1=[] \n",
    "        windows=[]\n",
    "        for i in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(i)\n",
    "            if cv2.contourArea(i)>25:  #Remove small connected areas\n",
    "                #x, y, w, h = cv2.boundingRect(i)\n",
    "                contours1.append(i)\n",
    "                for m,n in zip(contours1,range(len(contours1))):\n",
    "                    M = cv2.moments(m)\n",
    "                    x,y,w,h=cv2.boundingRect(m)\n",
    "                    windows.append((x,y,x+w,y+h))\n",
    "        return windows\n",
    "    \n",
    "    def rect_center(self,frame):\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #Find connected domains\n",
    "            #comparing the area of connected domains\n",
    "        contours1=[] \n",
    "        windows_center=[]\n",
    "        for i in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(i)\n",
    "            if cv2.contourArea(i)>25:  #Remove small connected areas\n",
    "                #x, y, w, h = cv2.boundingRect(i)\n",
    "                contours1.append(i)\n",
    "                for m,n in zip(contours1,range(len(contours1))):\n",
    "                    M = cv2.moments(m)\n",
    "                    x,y,w,h=cv2.boundingRect(m)\n",
    "                    cx=int(x+w/2.0)\n",
    "                    cy=int(y+h/2.0)\n",
    "                    windows_center.append((cx,cy))\n",
    "        return windows_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "    #def __init__(self):\n",
    "        #self.bg=cv2.cv2.createBackgroundSubtractorMOG2()\n",
    "    def Detect(self,frame,f_centers,centers):\n",
    "        imgO=normalize(frame)\n",
    "        imgO_1=cv2.cvtColor(imgO,cv2.COLOR_BGR2GRAY)\n",
    "        ret0,thresh0 = cv2.threshold(imgO_1,0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            # Deal with the situation where cells are connected together\n",
    "        d,contours,hirearchy=cv2.findContours(thresh0, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        centers=[]\n",
    "        r_thresh=4\n",
    "        r=[]\n",
    "        for i in contours:\n",
    "            (x,y),radius=cv2.minEnclosingCircle(i)\n",
    "            radius=int(radius)\n",
    "            if radius>r_thresh:\n",
    "                b=np.array((x,y))\n",
    "                centers.append(np.round(b))\n",
    "                r.append(radius)\n",
    "        #D=dist.cdist(f_centers,centers)\n",
    "        '''\n",
    "        f=D<30\n",
    "        for row in range(len(f_centers)):\n",
    "            for c in range(len(centers)):\n",
    "                if (D[row][c]<30) and (D[row][c]!=0):\n",
    "                    c1=(int(centers[row][0]),int(centers[row][1]))\n",
    "                    c2=(int(centers[c][0]),int(centers[c][1]))\n",
    "                    r1=r[row]\n",
    "                    r2=r[c]\n",
    "                if (f[row][c]) and (D[row][c]!=0) and ((r[row])<16 and (r[c]<16)):\n",
    "                    c1=(int(centers[row][0]),int(centers[row][1]))\n",
    "                    c2=(int(centers[c][0]),int(centers[c][1]))\n",
    "                    cv2.circle(frame,c1,r[row],(0,255,0),2)\n",
    "                    cv2.circle(frame,c2,r[c],(0,255,0),2)\n",
    "                else:\n",
    "                    c1=(int(centers[row][0]),int(centers[row][1]))\n",
    "                    cv2.circle(frame,c1,r[row],(0,0,255),2)\n",
    "        '''        \n",
    "        return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_img(img):\n",
    "    return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    img = image.copy().astype(np.float32)\n",
    "    img -= np.mean(img)\n",
    "    img /= np.linalg.norm(img)\n",
    "    img = np.clip(img, 0, 255)\n",
    "    img *= (1./float(img.max()))\n",
    "    return (img*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    sequence_tif = {}\n",
    "    gary_seq_tif = {}\n",
    "    for root, dirs, files, in os.walk(path):\n",
    "        dirs.sort()\n",
    "        for dir in dirs:\n",
    "            sequence_tif[dir] = []\n",
    "            gary_seq_tif[dir] = []\n",
    "            for _, _, files_1 in os.walk(os.path.join(path, dir)):\n",
    "                files_1.sort()\n",
    "                for file in files_1:\n",
    "                    new_dir_path = os.path.join(path, dir)\n",
    "                    temp_img = cv2.imread(os.path.join(new_dir_path, file))\n",
    "                    gray_imgs = gray_img(temp_img.copy())\n",
    "                    sequence_tif[dir].append(temp_img)\n",
    "                    gary_seq_tif[dir].append(gray_imgs)\n",
    "\n",
    "    return sequence_tif,gary_seq_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_cells(sequence):\n",
    "    detector=CentroidTracker()\n",
    "    cell=Features()\n",
    "    for k in range(len(sequence)):\n",
    "        #former_list_centers=[]\n",
    "        frame=sequence[k]\n",
    "        f=copy.copy(frame)\n",
    "        window=cell.rect_window(f)\n",
    "        objects = detector.update(window)\n",
    "        list_objects=list(objects.items())\n",
    "        present_centers=cell.centercells(f)\n",
    "        \n",
    "        min_dist=[]\n",
    "        num_present_centers=[]\n",
    "        num_former_centers=[]\n",
    "        match_num=[]\n",
    "        match_present=[]\n",
    "        \n",
    "        if k==0:\n",
    "            former_list_centers=cell.centercells(f)\n",
    "            '''\n",
    "            for item in list_objects:\n",
    "                former_list_centers.append(item[1])\n",
    "            '''\n",
    "            for (objectID, centroid) in objects.items():\n",
    "               # cv2.putText(f, text, (centroid[0] - 10, centroid[1] - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                cv2.circle(f, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "        else:\n",
    "            former_list_centers=centers\n",
    "            '''\n",
    "            D=dist.cdist(np.array(former_list_centers),present_centers,metric='euclidean')\n",
    "            D_list=D.tolist()\n",
    "            for l in range(len(D_list)):\n",
    "                for (n,d) in enumerate(D_list[l]):\n",
    "                    if d==min(D_list[l]):\n",
    "                        min_dist.append((n,d))\n",
    "            for (num,(cx,cy)) in enumerate(present_centers):\n",
    "                num_present_centers.append((num,(cx,cy)))\n",
    "            for (num,(cx,cy)) in enumerate(former_list_centers):\n",
    "                num_former_centers.append((num,(cx,cy)))\n",
    "            for i in range(len(min_dist)):\n",
    "                for j in range(len(num_present_centers)):\n",
    "                    if min_dist[i][0]==num_present_centers[j][0]:  \n",
    "                        #match_num.append(j)\n",
    "                        cv2.line(f,former_list_centers[i],num_present_centers[j][1],(0,0,255),2)\n",
    "            \n",
    "            for i in range(len(match_num)):\n",
    "                for j in range(len(num_present_centers)):\n",
    "                    if match_num[i]==num_present_centers[j][0]:\n",
    "                        match_present.append(num_present_centers[j][1])\n",
    "            for i in range(len(former_list_centers)):\n",
    "                cv2.line(f,former_list_centers[i],match_present[i],(0,0,255),2)\n",
    "            '''\n",
    "        centers=cell.centercells(f)\n",
    "        D=dist.cdist(np.array(former_list_centers),centers,metric='euclidean') \n",
    "        for i in range(len(former_list_centers)):\n",
    "            for j in range(len(centers)):\n",
    "                if D[i][j]<10.0:\n",
    "                    cv2.line(f,former_list_centers[i],centers[j],(0,0,255),2)\n",
    "        #print(D_list)\n",
    "        plt.imsave('trackingline0_'+str(k)+'.jpg',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/admin/Downloads/COMP9517 20T2 Group Project Image Sequences-4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path2=path+'PhC-C2DL-PSC'\n",
    "original_img,grays=read_img(path2)\n",
    "\n",
    "tracking_cells(original_img['Sequence 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
